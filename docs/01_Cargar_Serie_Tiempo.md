# 01_Cargar_Serie_Tiempo

ğŸ¯ **PropÃ³sito Principal**

Este notebook toma el dataset original y lo convierte en una **serie temporal agregada** a frecuencia de **1 minuto**, apta para anÃ¡lisis posterior. En tÃ©rminos simples: pasa de una tabla de flujos con timestamps a una â€œlÃ­nea de tiempoâ€ que permite observar cÃ³mo cambia el trÃ¡fico con el tiempo.

Su objetivo es dejar dos productos listos:

1. un **dataset limpio** (columnas normalizadas y timestamp convertido)
2. una **serie temporal** (por minuto) que serÃ¡ la base del EDA, modelado y detecciÃ³n por residuos.

ğŸ“‹ **Requisitos Previos**

Notebooks que debes ejecutar antes:

- `00_Cargar_dataset.ipynb` (si no cargas aquÃ­, este notebook igualmente lee el CSV)

Datos necesarios:

- Archivo: `../data/raw/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv` â†’ dataset original

Archivos que genera y luego se reutilizan:

- `../data/processed/dataset_limpio.csv` â†’ dataset limpio
- `../data/processed/serie_temporal.csv` â†’ serie temporal agregada por minuto
- `../results/01_paquetes_por_minuto.png` â†’ grÃ¡fico de validaciÃ³n

Herramientas requeridas:

- **Pandas / NumPy**: limpieza, agregaciÃ³n y resampleo
- **Matplotlib**: grÃ¡fico de control
- **Regex (re)**: normalizaciÃ³n de nombres de columnas
- **Datetime**: conversiÃ³n de timestamp

ğŸš€ **CÃ³mo Usar Este Notebook**

Pasos BÃ¡sicos:

1. **PreparaciÃ³n:** confirma rutas `../data/raw/`, `../data/processed/`, `../results/`
2. **EjecuciÃ³n:** corre todas las celdas en orden (hay dependencias entre pasos)
3. **VerificaciÃ³n:**
    - el timestamp queda en formato datetime
    - la serie temporal no tiene saltos raros
    - se genera el grÃ¡fico `01_paquetes_por_minuto.png`
4. **Siguientes pasos:** continÃºa con `02_EDA.ipynb`

â±ï¸ **Tiempos Estimados**

- EjecuciÃ³n completa: **3â€“7 minutos** (depende de hardware)
- Procesamiento de datos: **2â€“5 minutos**
- GeneraciÃ³n de resultados: **< 1 minuto**

ğŸ” **ExplicaciÃ³n por Secciones**

**SecciÃ³n 1: Carga del dataset**

- Objetivo: leer el CSV original y disponerlo como tabla
- Proceso: lectura con Pandas, revisiÃ³n inicial de columnas
- Salida esperada: DataFrame `df_trafico` cargado

**SecciÃ³n 2: NormalizaciÃ³n de columnas**

- Objetivo: estandarizar nombres de columnas para evitar errores posteriores
- Proceso: funciÃ³n `limpiar_col()` (string, strip, lower, underscores)
- Salida esperada: columnas consistentes (ej. `timestamp`, `total_fwd_packets`, etc.)
- Nota: esta secciÃ³n reduce errores por espacios y nombres inconsistentes

**SecciÃ³n 3: ConversiÃ³n de timestamp**

- Objetivo: convertir la columna `timestamp` a tipo fecha-hora
- Proceso: `pd.to_datetime()`
- Salida esperada: columna en datetime y tabla ordenable temporalmente
- Nota: si falla aquÃ­, el resampleo posterior queda invÃ¡lido

**SecciÃ³n 4: Limpieza de datos (control bÃ¡sico)**

- Objetivo: dejar un dataset consistente para agregaciÃ³n
- Proceso: revisiones generales (nulos, tipos)
- Salida esperada: dataset listo para agrupar

**SecciÃ³n 5: ConstrucciÃ³n de la serie temporal**

- Objetivo: agregar el trÃ¡fico en intervalos de 1 minuto
- Proceso: indexar por timestamp + resample/agrupaciÃ³n + suma/conteo segÃºn mÃ©trica
- Salida esperada: archivo `serie_temporal.csv`

**SecciÃ³n 6: ExportaciÃ³n**

- Objetivo: guardar productos intermedios para trazabilidad
- Proceso: exportar `dataset_limpio.csv` y `serie_temporal.csv`
- Salida esperada: archivos disponibles en `../data/processed/`

**SecciÃ³n 7: VerificaciÃ³n de continuidad temporal**

- Objetivo: confirmar que la serie tenga un eje temporal consistente
- Proceso: validaciones simples (rangos, frecuencia, nulos)
- Salida esperada: serie lista para EDA

**SecciÃ³n 8: GrÃ¡fico de validaciÃ³n**

- Objetivo: visualizar rÃ¡pidamente el comportamiento por minuto
- Proceso: generar y guardar el grÃ¡fico
- Salida esperada: `../results/01_paquetes_por_minuto.png`

ğŸ“Š **Resultados y Productos**

Archivos Generados:

- `../data/processed/dataset_limpio.csv` â†’ usado como base limpia
- `../data/processed/serie_temporal.csv` â†’ entrada directa del EDA y modelado
- `../results/01_paquetes_por_minuto.png` â†’ control visual del resampleo

Visualizaciones:

- GrÃ¡fico: â€œPaquetes por minutoâ€ â†’ confirma forma general y rangos

MÃ©tricas Clave:

- Longitud de serie: depende del rango temporal cubierto en el dataset
- Frecuencia: 1 minuto (controlada)

ğŸ”— **Conexiones con Otros Notebooks**

Dependencias (Entradas desde):

- `00_Cargar_dataset.ipynb` â†’ si ya cargaste/validaste el CSV

Salidas hacia (Alimenta a):

- `02_EDA.ipynb` â†’ usa `serie_temporal.csv`

âš ï¸ **Posibles Problemas y Soluciones**

Error ComÃºn 1: `KeyError: 'timestamp'`

- Causa probable: columna original con espacios o nombre distinto
- SoluciÃ³n: confirmar que la normalizaciÃ³n de columnas corriÃ³ antes del paso 3

Error ComÃºn 2: Timestamp no convierte (`ValueError`)

- Causa probable: formato inconsistente en la columna
- SoluciÃ³n: inspeccionar valores â€œrarosâ€ y ajustar `to_datetime(..., errors='coerce')`

Error ComÃºn 3: No se crea el archivo en `../data/processed/`

- Causa probable: carpeta no existe
- SoluciÃ³n: crear carpeta o ajustar ruta

ğŸ’¡ **Consejos PrÃ¡cticos**

Para optimizar el uso:

- No ejecutes celdas â€œsalteadasâ€; la serie depende de pasos previos

PersonalizaciÃ³n posible:

- Puedes cambiar la mÃ©trica base (siempre documentando el motivo) sin romper el flujo, pero el resto del pipeline debe usar la misma columna objetivo

â“ **Preguntas Frecuentes**

P: Â¿CÃ³mo sÃ© que la serie quedÃ³ bien?

R: Se genera el grÃ¡fico, el eje temporal es continuo y los valores no son â€œtodo ceroâ€ ni â€œtodo constanteâ€.

P: Â¿Necesito entender el resampleo?

R: Solo a nivel conceptual: estÃ¡s agrupando trÃ¡fico por minuto para observar tendencias.

ğŸ“ˆ **Aplicaciones PrÃ¡cticas**

- ConstrucciÃ³n de series temporales desde datos con timestamp
- PreparaciÃ³n reproducible de seÃ±ales para anÃ¡lisis estadÃ­stico

ğŸ”„ **Flujo de Trabajo Recomendado**

```
00_Cargar_dataset â†’ 01_Construccion_Serie_Tiempo â†’ 02_EDA
```

ğŸ“ **Soporte y Referencias**

Ãšltima actualizaciÃ³n: 2025-12-13