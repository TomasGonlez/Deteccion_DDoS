# 01_Construccion_Serie_Tiempo_1s

ğŸ¯ **PropÃ³sito Principal**

Este notebook replica el proceso de construcciÃ³n de serie temporal, pero usando una **frecuencia de 1 segundo**. Su finalidad es **explorar** cÃ³mo se ve la seÃ±al al aumentar la resoluciÃ³n temporal y evaluar si aporta valor para detectar cambios abruptos asociados a un ataque.

En el contexto de CICIDS2017 (basado en registros de flujos), esta versiÃ³n suele usarse como **experimento metodolÃ³gico**: permite observar si el resampleo fino produce una serie interpretable o si introduce distorsiÃ³n/fragmentaciÃ³n por la naturaleza del dataset.

ğŸ“‹ **Requisitos Previos**

Notebooks que debes ejecutar antes:

- `00_Cargar_dataset.ipynb` (opcional si aquÃ­ se lee el CSV)

Datos necesarios:

- `../data/raw/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv`

Archivos generados:

- `../data/processed/dataset_limpio.csv`
- `../data/processed/serie_temporal.csv` *(ojo: en tu caso el notebook genera salida asociada a â€œpor segundoâ€)*
- `../results/01_paquetes_por_segundo.png`

Herramientas requeridas:

- Pandas / NumPy / Matplotlib / re / datetime

ğŸš€ **CÃ³mo Usar Este Notebook**

Pasos BÃ¡sicos:

1. Ejecuta todas las celdas en orden
2. Verifica que la serie resultante tenga suficiente densidad (no demasiados ceros/gaps)
3. Usa el grÃ¡fico de control para evaluar si la seÃ±al es interpretable

â±ï¸ **Tiempos Estimados**

- EjecuciÃ³n completa: **5â€“12 minutos**
- Procesamiento de datos: **4â€“10 minutos**
- GeneraciÃ³n de resultados: **< 1 minuto**

ğŸ” **ExplicaciÃ³n por Secciones**

*(Mismas secciones que la versiÃ³n por minuto, pero cambiando la agregaciÃ³n temporal.)*

- SecciÃ³n 5 (ConstrucciÃ³n de serie) cambia a **resample por 1 segundo**
- SecciÃ³n 8 exporta `01_paquetes_por_segundo.png`

ğŸ“Š **Resultados y Productos**

Archivos Generados:

- `../results/01_paquetes_por_segundo.png` â†’ validaciÃ³n visual 1s

Visualizaciones:

- GrÃ¡fico por segundo â†’ Ãºtil para evaluar â€œgranularidad vs ruidoâ€

ğŸ”— **Conexiones con Otros Notebooks**

- No se recomienda como entrada del flujo principal salvo que TODO el pipeline se ajuste a esta frecuencia.

âš ï¸ **Posibles Problemas y Soluciones**

Error comÃºn: serie â€œvacÃ­aâ€ o con muchos ceros

- Causa: el dataset no tiene eventos densos por segundo en forma uniforme
- SoluciÃ³n: evaluar si la frecuencia es metodolÃ³gicamente conveniente o usar 1 minuto